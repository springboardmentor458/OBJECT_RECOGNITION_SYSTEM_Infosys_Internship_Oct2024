import albumentations as A
from albumentations.pytorch import ToTensorV2
from torch.utils.data import DataLoader

# Define the augmentation pipeline
augmentation_pipeline = A.Compose([
    A.Resize(416, 416),  # Resizing
    A.RandomBrightnessContrast(p=0.3),  # Brightness and Contrast Adjustment
    A.GaussianBlur(p=0.25),  # Blurring for image quality improvement
    A.HorizontalFlip(p=0.5),  # Horizontal Flip
    A.VerticalFlip(p=0.2),  # Vertical Flip
    A.Rotate(limit=25, p=0.5),  # Random Rotation
    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.4),  # Color adjustments
    A.ToGray(p=0.15),  # Randomly convert some images to grayscale
    A.CLAHE(p=0.2),  # Contrast Limited Adaptive Histogram Equalization
    A.RandomGamma(p=0.2),  # Random Gamma Adjustment
    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, min_holes=1, min_height=16, min_width=16, p=0.3),  # CoarseDropout augmentation
    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # Normalization
    ToTensorV2()  # Convert image to PyTorch tensor
], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['category_labels']))

image_directory = 'path_to_images_directory'
custom_dataset = CocoDataset(images, annotations, category_mapping, image_directory, transform=augmentation_pipeline)
data_loader = DataLoader(custom_dataset, batch_size=16, shuffle=True, collate_fn=lambda batch: tuple(zip(*batch)))

for img_batch, target_batch in data_loader:
    print(f"Images batch size: {len(img_batch)}")
    print(f"Target batch size: {len(target_batch)}")
    print("Sample target:", target_batch[0]) 
    break
