{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/springboardmentor458/OBJECT_RECOGNITION_SYSTEM_Infosys_Internship_Oct2024/blob/Harsha-Kota/springboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "J-i8C6UjAFKH"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python-headless albumentations torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLqLDVhjDwWn"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import json"
      ],
      "metadata": {
        "id": "6hkweBLvCR3c"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKl4KWnHC15B"
      },
      "source": [
        "Use this if you need all those images in folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tymPmUYxCEVj"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "import json\n",
        "import cv2\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "json_filename = '/content/drive/MyDrive/Colab Notebooks/instances_val2017.json'\n",
        "with open(json_filename, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "output_dir = '/content/output_images'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def download_and_save(image_url, annotations, filename):\n",
        "    resp = urllib.request.urlopen(image_url)\n",
        "    img_array = np.asarray(bytearray(resp.read()), dtype=np.uint8)\n",
        "    img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
        "    for ann in annotations:\n",
        "        x, y, w, h = ann['bbox']\n",
        "        cv2.rectangle(img, (int(x), int(y)), (int(x+w), int(y+h)), (255, 0, 0), 2)\n",
        "    output_path = os.path.join(output_dir, filename)\n",
        "    cv2.imwrite(output_path, img)\n",
        "\n",
        "for img_data in data['images']:\n",
        "    img_id = img_data['id']\n",
        "    img_url = img_data['coco_url']\n",
        "    filename = img_data['file_name']\n",
        "    annotations = [ann for ann in data.get('annotations', []) if ann['image_id'] == img_id]\n",
        "    download_and_save(img_url, annotations, filename)\n",
        "\n",
        "print(f\"All images saved in {output_dir}\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juF4bqxVCw7H"
      },
      "source": [
        "Use This for Direct Representations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wStW0cFZCuVJ"
      },
      "outputs": [],
      "source": [
        "# Cell 1\n",
        "import json\n",
        "import cv2\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "json_filename = '/content/drive/MyDrive/Colab Notebooks/instances_val2017.json'\n",
        "with open(json_filename, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "def download_and_display(image_url, annotations, image=None):\n",
        "    resp = urllib.request.urlopen(image_url)\n",
        "    img_array = np.asarray(bytearray(resp.read()), dtype=np.uint8)\n",
        "    img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
        "\n",
        "    if image is not None:\n",
        "        img = image\n",
        "\n",
        "    for ann in annotations:\n",
        "        x, y, w, h = ann['bbox']\n",
        "        cv2.rectangle(img, (int(x), int(y)), (int(x+w), int(y+h)), (255, 0, 0), 2)\n",
        "\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Get the user input for the number of images to load\n",
        "num_images = int(input(\"Enter the number of images to load (default is all): \") or len(data['images']))\n",
        "\n",
        "original_images = []\n",
        "original_annotations = []\n",
        "\n",
        "for i, img_data in enumerate(data['images']):\n",
        "    if i >= num_images:\n",
        "        break\n",
        "    img_id = img_data['id']\n",
        "    img_url = img_data['coco_url']\n",
        "    annotations = [ann for ann in data.get('annotations', []) if ann['image_id'] == img_id]\n",
        "    original_images.append(img_url)\n",
        "    original_annotations.append(annotations)\n",
        "    download_and_display(img_url, annotations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DS_P_m3hwj5J"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "def process_and_display_images(original_images, original_annotations):\n",
        "    def draw_annotations(image, annotations):\n",
        "        # Create a copy of the image to avoid modifying the original\n",
        "        annotated_img = image.copy()\n",
        "        for ann in annotations:\n",
        "            x, y, w, h = ann['bbox']\n",
        "            cv2.rectangle(annotated_img,\n",
        "                         (int(x), int(y)),\n",
        "                         (int(x+w), int(y+h)),\n",
        "                         (255, 0, 0), 2)\n",
        "        return annotated_img\n",
        "\n",
        "    def create_image_grid(images, titles, num_cols=3):\n",
        "        num_images = len(images)\n",
        "        num_rows = (num_images + num_cols - 1) // num_cols\n",
        "\n",
        "        fig = plt.figure(figsize=(15, 5 * num_rows))\n",
        "        gs = GridSpec(num_rows, num_cols, figure=fig)\n",
        "\n",
        "        for idx, (img, title) in enumerate(zip(images, titles)):\n",
        "            row = idx // num_cols\n",
        "            col = idx % num_cols\n",
        "            ax = fig.add_subplot(gs[row, col])\n",
        "\n",
        "            if len(img.shape) == 2:  # If grayscale\n",
        "                # Convert grayscale to BGR for annotation\n",
        "                img_color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "                ax.imshow(cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB))\n",
        "            else:  # If color\n",
        "                ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "            ax.set_title(title)\n",
        "            ax.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    for img_url, annotations in zip(original_images, original_annotations):\n",
        "        # Download and process each image\n",
        "        resp = urllib.request.urlopen(img_url)\n",
        "        img_array = np.asarray(bytearray(resp.read()), dtype=np.uint8)\n",
        "        img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
        "\n",
        "        # Process images with different techniques\n",
        "        processed_images = []\n",
        "        titles = []\n",
        "\n",
        "        # 1. Original Image with annotations\n",
        "        annotated_original = draw_annotations(img, annotations)\n",
        "        processed_images.append(annotated_original)\n",
        "        titles.append('Original Image with Annotations')\n",
        "\n",
        "        # 2. Binary Image with annotations\n",
        "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        binary_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "        binary_img_color = cv2.cvtColor(binary_img, cv2.COLOR_GRAY2BGR)\n",
        "        annotated_binary = draw_annotations(binary_img_color, annotations)\n",
        "        processed_images.append(annotated_binary)\n",
        "        titles.append('Binary Image with Annotations')\n",
        "\n",
        "        # 3. Resized Image with annotations\n",
        "        resized_img = cv2.resize(img, (224, 224))\n",
        "        # Scale annotations for resized image\n",
        "        scale_x = 224.0 / img.shape[1]\n",
        "        scale_y = 224.0 / img.shape[0]\n",
        "        scaled_annotations = []\n",
        "        for ann in annotations:\n",
        "            scaled_ann = ann.copy()\n",
        "            x, y, w, h = ann['bbox']\n",
        "            scaled_ann['bbox'] = [x * scale_x, y * scale_y, w * scale_x, h * scale_y]\n",
        "            scaled_annotations.append(scaled_ann)\n",
        "        annotated_resized = draw_annotations(resized_img, scaled_annotations)\n",
        "        processed_images.append(annotated_resized)\n",
        "        titles.append('Resized Image (224x224) with Annotations')\n",
        "\n",
        "        # 4. Rotated Image with annotations (portrait orientation images will rotate.)\n",
        "        height, width, _ = img.shape\n",
        "        if height > width:              # If you want to rotate all images regardless of their orientation remove the line or adjust\n",
        "            rotated_img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
        "            # Adjust annotations for rotation\n",
        "            rotated_annotations = []\n",
        "            for ann in annotations:\n",
        "                rotated_ann = ann.copy()\n",
        "                x, y, w, h = ann['bbox']\n",
        "                rotated_ann['bbox'] = [y, width - x - w, h, w]\n",
        "                rotated_annotations.append(rotated_ann)\n",
        "            rotation_status = \"Rotated 90°\"\n",
        "            annotated_rotated = draw_annotations(rotated_img, rotated_annotations)\n",
        "        else:\n",
        "            rotated_img = img\n",
        "            rotation_status = \"No Rotation Needed\"\n",
        "            annotated_rotated = draw_annotations(rotated_img, annotations)\n",
        "        processed_images.append(annotated_rotated)\n",
        "        titles.append(f'Orientation Check\\n({rotation_status})')\n",
        "\n",
        "        # 5. Sharpened Image with annotations\n",
        "        sharpened_img = cv2.GaussianBlur(rotated_img, (0, 0), sigmaX=1, sigmaY=1)\n",
        "        sharpened_img = cv2.addWeighted(rotated_img, 1.5, sharpened_img, -0.5, 0)\n",
        "        annotated_sharpened = draw_annotations(sharpened_img,\n",
        "                                             rotated_annotations if height > width else annotations)\n",
        "        processed_images.append(annotated_sharpened)\n",
        "        titles.append('Sharpened Image with Annotations')\n",
        "\n",
        "        # 6. Black and White Image with annotations\n",
        "        bw_img = cv2.cvtColor(sharpened_img, cv2.COLOR_BGR2GRAY)\n",
        "        bw_img_color = cv2.cvtColor(bw_img, cv2.COLOR_GRAY2BGR)\n",
        "        annotated_bw = draw_annotations(bw_img_color,\n",
        "                                      rotated_annotations if height > width else annotations)\n",
        "        processed_images.append(annotated_bw)\n",
        "        titles.append('Black & White Image with Annotations')\n",
        "\n",
        "        # Display grid for current image\n",
        "        create_image_grid(processed_images, titles)\n",
        "\n",
        "# Usage:\n",
        "processed_images, processed_annotations = process_and_display_images(original_images, original_annotations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dAVQNJlnvH6R"
      },
      "outputs": [],
      "source": [
        "# Cell 2(first success)\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def process_images(original_images, original_annotations):\n",
        "    processed_images = []\n",
        "    processed_annotations = []\n",
        "\n",
        "    for img_url, annotations in zip(original_images, original_annotations):\n",
        "        resp = urllib.request.urlopen(img_url)\n",
        "        img_array = np.asarray(bytearray(resp.read()), dtype=np.uint8)\n",
        "        img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
        "\n",
        "        # Filter images\n",
        "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        binary_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "        # Resize images\n",
        "        resized_img = cv2.resize(img, (224, 224))\n",
        "\n",
        "        # Test for correct orientation\n",
        "        height, width, _ = img.shape\n",
        "        if height > width:\n",
        "            rotated_img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
        "        else:\n",
        "            rotated_img = img\n",
        "\n",
        "        # Fix blurry images\n",
        "        sharpened_img = cv2.GaussianBlur(rotated_img, (0, 0), sigmaX=1, sigmaY=1)\n",
        "        sharpened_img = cv2.addWeighted(rotated_img, 1.5, sharpened_img, -0.5, 0)\n",
        "\n",
        "        # Apply filters (e.g., black and white)\n",
        "        bw_img = cv2.cvtColor(sharpened_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        processed_images.extend([img, binary_img, resized_img, rotated_img, sharpened_img, bw_img])\n",
        "        processed_annotations.extend([annotations] * 6)\n",
        "\n",
        "    return processed_images, processed_annotations\n",
        "\n",
        "# Call the processing function with the data from the previous cell\n",
        "processed_images, processed_annotations = process_images(original_images, original_annotations)\n",
        "\n",
        "# Display the processed images\n",
        "for i, (img, annotations) in enumerate(zip(processed_images, processed_annotations)):\n",
        "    download_and_display(original_images[i % len(original_images)], annotations, image=img)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CocoDataset(Dataset):\n",
        "    def __init__(self, images, annotations, category_mapping, img_dir, transform=None):\n",
        "        self.images = images\n",
        "        self.annotations = annotations\n",
        "        self.category_mapping = category_mapping\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.image_id_to_annotations = self._group_annotations_by_image()\n",
        "    def _group_annotations_by_image(self):\n",
        "        image_id_to_annotations = {}\n",
        "        for ann in self.annotations:\n",
        "            image_id = ann['image_id']\n",
        "            if image_id not in image_id_to_annotations:\n",
        "                image_id_to_annotations[image_id] = []\n",
        "            image_id_to_annotations[image_id].append(ann)\n",
        "        return image_id_to_annotations\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    def __getitem__(self, idx):\n",
        "        image_info = self.images[idx]\n",
        "        img_path = os.path.join(self.img_dir, image_info['/content/drive/MyDrive/Colab Notebooks/instances_val2017.json'])\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "\n",
        "        # Get annotations\n",
        "        image_id = image_info['id']\n",
        "        annotations = self.image_id_to_annotations.get(image_id, [])\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        for ann in annotations:\n",
        "            x, y, width, height = ann['bbox']\n",
        "            boxes.append([x, y, x + width, y + height])\n",
        "            labels.append(ann['category_id'])\n",
        "      # Convert boxes and labels to numpy arrays for Albumentations\n",
        "        boxes = np.array(boxes)\n",
        "        labels = np.array(labels)\n",
        "\n",
        "        # Apply transformations\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=image, bboxes=boxes, labels=labels)\n",
        "            image = transformed['image']\n",
        "            boxes = transformed['bboxes']\n",
        "            labels = transformed['labels']\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.tensor(labels, dtype=torch.int64)\n",
        "        target = {\"boxes\": boxes, \"labels\": labels}\n",
        "\n",
        "        return image, target"
      ],
      "metadata": {
        "id": "nwn0GLBPCuuR"
      },
      "execution_count": 8,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}